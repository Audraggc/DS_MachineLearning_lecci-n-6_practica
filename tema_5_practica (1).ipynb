{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a25e8dc1-82d1-4e58-9eec-4f67fb3396c3",
   "metadata": {},
   "source": [
    "# Practica Tema 5: Construcción de un flujo de trabajo para problemas de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372b92ea-38b9-41e2-8d23-4e06b489af81",
   "metadata": {},
   "source": [
    "Para la siguiente práctica vas a aplicar todos los conceptos y el código que revisaste en el tema 5. Vas a trabajar con el código y los datos del Call Center."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeeca33-dd34-4bb5-a7bb-f7385b268ec0",
   "metadata": {},
   "source": [
    "## Pregunta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95376e10-23f5-494d-a56c-5beaf97cda58",
   "metadata": {},
   "source": [
    "El flujo de trabajo que hemos revisado hasta este momento nos ha permitido optimizar y evaluar un xgboost para clasificar a los clientes de un banco en quiénes sí aceptarían un depósito a plazo y quiénes no. Utiliza Google Colab y repite el mismo flujo de trabajo para optimizar y evaluar un xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36111fa-b689-41c3-a0a6-6b067e07242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar versiones de pandas y yellowbrick\n",
    "# Instalar última versión de yellowbrick y sklearn\n",
    "!pip install yellowbrick==1.3.post1\n",
    "!pip install scikit-learn==0.24.2\n",
    "!pip install dtreeviz==1.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3def1a5d-f843-44ba-9b1c-c7087a589adf",
   "metadata": {},
   "source": [
    "### Cargar datos y preprocesar datos crudos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285f648c-8b21-4210-86b5-99fec943ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# importar librerías estándar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotnine import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41fff99-e77e-4aba-a6b1-6e4005e44dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar funciones de preprocesamiento\n",
    "def fun_preprocess_numeric_variables(df):\n",
    "    '''Regresa un data frame con las variables numéricas preprocesadas.\n",
    "    \n",
    "    Codificar mes como una variable numéricas\n",
    "    Seleccionar el resto de las varaibles numéricas.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "        DataFrame con los datos del banco.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        DataFrame con los campos numéricos preprocesados . \n",
    "    '''\n",
    " \n",
    "    month_enc = {\n",
    "        'jan':1, 'feb':2, 'mar':3, 'apr':4, 'may':5, 'jun':6, \n",
    "        'jul':7, 'aug':8, 'sep':9, 'oct':10, 'nov':11, 'dec':12\n",
    "    }\n",
    "    df_month = df.month.map(month_enc).to_frame()\n",
    "    df_numeric = df[['day', 'duration', 'campaign', 'pdays', 'previous']]\n",
    "    \n",
    "    return pd.concat([df_month, df_numeric], axis = 1)\n",
    "\n",
    "def fun_preprocess_categorical_variables(df):\n",
    "    '''Regresar un data frame con las variables categóricas preprocesadas.\n",
    "\n",
    "    Convierte en dummies las variables categóricas (loan, housing, marital contact, \n",
    "    unknown, other, education y job). \n",
    "    En algunos casos recodifica algunas categorías con replace.\n",
    "    Para una variable categórica se elimina la primera opción con drop_first\n",
    "    esto es para evitar problemas de multicolinealidad en algunos algorítmos.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "        DataFrame con los datos del banco.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        DataFrame con los campos categóricos preprocesados.  \n",
    "    '''\n",
    "    \n",
    "    df_loans = pd.get_dummies(df[['loan', 'housing', 'default']], drop_first = True)\n",
    "    df_marital = pd.get_dummies(df[['marital']], drop_first = True)\n",
    "    df_contact = pd.get_dummies(df[['contact']], drop_first = True)\n",
    "    df_outcome = pd.get_dummies(\n",
    "        df.poutcome.replace({'unknown':'other'}), \n",
    "        drop_first=True, \n",
    "        prefix = 'poutcome'\n",
    "    )\n",
    "    df_education = pd.get_dummies(\n",
    "        df.education.replace(\n",
    "            {'primary':'not undergraduate', 'secondary':'not undergraduate', \n",
    "             'unknown':'not undergraduate', 'tertiary':'undergraduate'}), \n",
    "        prefix = 'education', \n",
    "        drop_first=True\n",
    "    )\n",
    "    df_job = pd.get_dummies(\n",
    "        df.job.replace(\n",
    "            {'unknown':'other', 'unemployed':'other', 'housemaid':'other', \n",
    "             'entrepreneur':'other', 'student':'other', 'self-employed':'other'}), \n",
    "        prefix = 'job', \n",
    "        drop_first=True\n",
    "    ) \n",
    "    return pd.concat([df_loans, df_marital, df_contact, df_outcome, df_education, df_job], axis = 1)\n",
    "\n",
    "def fun_preprocesar_atributos(df):\n",
    "    '''Regresa un DataFrame con los datos numéricos y categóricos preprocesados\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "        DataFrame con los datos del banco.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        DataFrame con los datos preprocesados\n",
    "    '''\n",
    "    df_numeric = fun_preprocess_numeric_variables(df) \n",
    "    df_categorical = fun_preprocess_categorical_variables(df)\n",
    "    \n",
    "    return pd.concat([df_numeric, df_categorical], axis = 1)\n",
    "\n",
    "def fun_preprocesar_categoria(df):\n",
    "    '''Regresa un numpy array con la variable dependiente\n",
    "    \n",
    "    Toma los datos del banco, extrae la variable dependiente,\n",
    "    la convierte en una variable de dummy donde:\n",
    "        1 = el cliente sí aceptó el depósito a plazo\n",
    "        0 = el cliente no aceptó el depósito a plazo\n",
    "        \n",
    "    Asimismo, se convierten los datos a int64 y se formata el\n",
    "    array para que tenga la siguiente dimensión (n, )\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "        DataFrame con los datos del banco.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        Regresa un numpy array con dimensión (n, ) con la variable\n",
    "        dependiente que toma valores de 1 y 0.\n",
    "    '''\n",
    "    \n",
    "    return pd.get_dummies(df.y, drop_first=True).astype('int64').values.ravel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28077f8f-d30e-49ce-83cd-c19f24c85b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "test_set = pd.read_csv(\"data/test.csv\", sep=\";\")\n",
    "train_full = pd.read_csv(\"data/train.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3107c3fb-7efb-42a2-acda-c76ca483a53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir los conjuntos de entrenamiento y validación\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, validation_set = train_test_split(\n",
    "    train_full,\n",
    "    test_size = test_set.shape[0],\n",
    "    stratify=train_full.y,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f41dc3-aace-43f2-9f42-0a3db54a2f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesar los conjuntos\n",
    "X_train = fun_preprocesar_atributos(train_set)\n",
    "y_train = fun_preprocesar_categoria(train_set)\n",
    "\n",
    "X_val = fun_preprocesar_atributos(validation_set)\n",
    "y_val = fun_preprocesar_categoria(validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b76bcb5-1d45-4983-8684-4bca4c49e6a4",
   "metadata": {},
   "source": [
    "### Ajustar modelo\n",
    "\n",
    "**TODO**\n",
    "\n",
    "* Construye un xgboost.\n",
    "* Explora los hiperparámetros utilizando RandomSearch.\n",
    "* Recupera el mejor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1118385-c4d8-4bbd-b32b-dcf687e01837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construye y ajusta un xgboost utilizando random search\n",
    "import xgboost as xgb\n",
    "# Especificamos el modelo \n",
    "# (Ojo, este algorítmo usa otros nombres para los parámetros)\n",
    "clf_xgb = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\t\t# Para un problema de clasificación binaria\n",
    "    eval_metric='auc',\t\t\t\t\t# Métrica de evaluación\n",
    "    scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1]),\n",
    "    \t\t\t\t\t\t\t\t\t# scale_pos_weight es el parámetro para \n",
    "    \t\t\t\t\t\t\t\t\t# reponderar las categorías con desbalance.\n",
    "    use_label_encoder=False,\t\t\t# Hay que indicar esta opción\n",
    "    random_state=42\t\t\t\t\t# Fijar semilla para reproducibilidad\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea81a78-54a3-4c7b-8e86-37c3828e65f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especifica los parámetros a explorar. \n",
    "# Tal vez necesitas revisar la documentación de xgboost para \n",
    "# comprender como funcionan los hiperparámetros.\n",
    "# https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':____________,\n",
    "    'learning_rate':____________,\n",
    "    'max_depth':____________,\n",
    "    'subsample':____________,\n",
    "    'colsample_bytree':____________,\n",
    "    'colsample_bylevel':____________,\n",
    "    'reg_lambda':____________\n",
    "}\n",
    "\n",
    "grid_search = RandomizedSearchCV(\n",
    "\tclf_xgb,\t\t\t\t\t# Especificar el modelo (estimador) \n",
    "\tparams,\t\t\t\t\t\t# Especificar los parámetros de la malla \n",
    "\tscoring = 'roc_auc', \t\t# Especificar la métrica de evaluación\n",
    "\tcv = 10,\t\t\t\t\t# Especificar los k-cortes de la validación cruzada \n",
    "\tn_iter=50,\t\t\t\t\t# Especificar número de modelos a explorar aleatoriamente \n",
    "    return_train_score=True,# Agregar el error de entrenamiento\n",
    "\tn_jobs=-1\t\t\t\t\t# Especificar el número de CPUs para paralelizar el trabajo\n",
    "    \t\t\t\t\t\t\t# -1= todos los disponibles\n",
    ")\n",
    "# Entrenar los modelos\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f051bf-22b9-45a7-9224-6ffe4f394e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga las funciones para imprimir los resultados del random search\n",
    "def fun_plot_grid_search_results(df):   \n",
    "    '''Regresa un DataFrame con los resultados de la exploración de hiperparámetros.\n",
    "\n",
    "    Esta función muestra una tabla estilizada con los resultados de la exploración de\n",
    "    hiper parámetros utilizando validación cruzada.\n",
    "    \n",
    "    En la tabla aparecen del lado izquierdo la combinación de hiperparámetros, el error\n",
    "    de entrenamiento y el error de validación cruzada y el ranking del mejor modelo\n",
    "    a partir del error de validación.\n",
    "    \n",
    "    El mapa de color va de azul (modelos con menor error) a rojo (modelos con mayor error).\n",
    "    Se calcula para el error de entrenamiento y validación de manera separada.\n",
    "    \n",
    "    Los resultados están ordenados de mejor a peor modelo, en función del error de validación.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dict: Diccionario con los resultados de la búsqueda de hiperparámetros GridSearchCV.cv_results_ \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.io.formats.style.Styler\n",
    "        Regresa una tabla estilizada con los resultados de la búsqueda de hiperparámetros.\n",
    "    '''\n",
    "    # Elegir paleta divergente de colores\n",
    "    cm = sns.diverging_palette(5, 250, as_cmap=True)\n",
    "    \n",
    "    return (\n",
    "        pd.concat([\n",
    "            # Limpiar la columna de parámetros\n",
    "            df['params'].apply(pd.Series), \n",
    "            # Extraer solamente el error de prueba \n",
    "            df[['mean_train_score', 'mean_test_score', 'rank_test_score']]],\n",
    "            axis = 1\n",
    "        )\n",
    "        # Ordenar los modelos de mejor a peor\n",
    "        .sort_values(by = 'rank_test_score')\n",
    "        # Pintar el fondo de la celda a partir del error de validación\n",
    "        .style.background_gradient(cmap=cm, subset = ['mean_train_score', 'mean_test_score'])\n",
    "    )\n",
    "\n",
    "def fun_resumen_grid_search(grid_search):\n",
    "    '''Imprime un resumen del grid search.\n",
    "    \n",
    "    Imprime el número de modelos que se entrenaron y \n",
    "    devuelve los hiperparámetros del mejor modelo.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    grid_search (GridSearchCV): Fitted GridSearch con los resultados.\n",
    "    '''\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"\\nSe evaluaron {} modelos utilizando el grid search.\".format(pd.DataFrame(grid_search.cv_results_).shape[0]))\n",
    "    print(\"\\nLos hiperparámetros del mejor modelo son: \" + str(best_params) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d4432a-e65d-467e-a08e-bf923502a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recupearar los resultados de la validación cruzada\n",
    "df_best_params = pd.DataFrame(grid_search.cv_results_)\n",
    "tabla_resultados = fun_plot_grid_search_results(df_best_params)\n",
    "tabla_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da38012-5b34-4ae3-a818-37260e9fdc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuepar los resultados de la validación cruzada.\n",
    "fun_resumen_grid_search(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6255081-64b8-4420-afd6-0a46966f08f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperar el estimador del mejor modelo.\n",
    "best_model_xgb = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3880942-217c-4c57-9651-eaeea5e94dd2",
   "metadata": {},
   "source": [
    "### Evaluación\n",
    "\n",
    "**TODO**\n",
    "* Construye una matriz de confusión.\n",
    "* Construye un reporte de clasificación.\n",
    "* Construye una curva de precision-recall\n",
    "* Construye una curva ROC\n",
    "* Calcula el ROC-AUC score\n",
    "* Construye una curva de discriminación del punto de corte.\n",
    "* Ajustarías el punto de corte, evalúa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fc801d-0921-43c3-961b-8c3dad0378c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar funciones especiales para evaluar los modelos de clasificación.\n",
    "from yellowbrick.classifier.threshold import DiscriminationThreshold\n",
    "from yellowbrick.classifier import (\n",
    "    ConfusionMatrix, ClassPredictionError, ClassificationReport,\n",
    "    PrecisionRecallCurve, ROCAUC, ClassPredictionError\n",
    ")\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def fun_graficar_matriz_confusion(model, X_val_test, y_val_test):\n",
    "    '''Graficar matriz de confusión\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model (Estimator): Fitted estimator\n",
    "    X_test (DataFrame): Predictores del conjunto de validación o prueba.\n",
    "    y_test (ndarray): Clases del conjunto de validación o prueba.\n",
    "    ''' \n",
    "    fig, ax = plt.subplots(figsize = (5,5))\n",
    "    cm = ConfusionMatrix(\n",
    "        model,\n",
    "        classes=['no', 'yes']\n",
    "    )\n",
    "    cm.fit(X_train, y_train)\n",
    "    cm.score(X_val_test, y_val_test)\n",
    "    cm.show();\n",
    "    \n",
    "def fun_graficar_reporte_clasificacion(model, X_val_test, y_val_test):\n",
    "    '''Graficar reporte de clasificación\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model (Estimator): Fitted estimator\n",
    "    X_test (DataFrame): Predictores del conjunto de validación o prueba.\n",
    "    y_test (ndarray): Clases del conjunto de validación o prueba.\n",
    "    '''   \n",
    "    fig, ax = plt.subplots(figsize = (6,5))\n",
    "    visualizer = ClassificationReport(\n",
    "        model,\n",
    "        classes=['no', 'yes']\n",
    "    )\n",
    "    visualizer.fit(X_train, y_train)\n",
    "    visualizer.score(X_val_test, y_val_test)\n",
    "    visualizer.show();  \n",
    "    \n",
    "def fun_graficar_curva_precision_recall(model, X_val_test, y_val_test):\n",
    "    '''Graficar curva de precision y recall\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model (Estimator): Fitted estimator\n",
    "    X_test (DataFrame): Predictores del conjunto de validación o prueba.\n",
    "    y_test (ndarray): Clases del conjunto de validación o prueba.\n",
    "    '''\n",
    "    fig, ax = plt.subplots(figsize = (6,6))\n",
    "    viz = PrecisionRecallCurve(model)\n",
    "    viz.fit(X_train, y_train)\n",
    "    viz.score(X_val_test, y_val_test)\n",
    "    viz.show();\n",
    "    \n",
    "def fun_graficar_curva_roc(model, X_val_test, y_val_test):\n",
    "    '''Graficar curva ROC\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model (Estimator): Fitted estimator\n",
    "    X_test (DataFrame): Predictores del conjunto de validación o prueba.\n",
    "    y_test (ndarray): Clases del conjunto de validación o prueba.\n",
    "    '''\n",
    "    fig, ax = plt.subplots(figsize = (6,6))\n",
    "    roc_curves_visualizer = ROCAUC(\n",
    "        model,\n",
    "        classes=['no', 'yes']\n",
    "    )\n",
    "    roc_curves_visualizer.fit(X_train, y_train)\n",
    "    roc_curves_visualizer.score(X_val, y_val) \n",
    "    roc_curves_visualizer.show();\n",
    "    \n",
    "def fun_imprimir_roc_auc_score(model, X_val_test, y_val_test):\n",
    "    '''Imprime el ROC AUC score\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model (Estimator): Fitted estimator de un DecisionTree, Random Forest o xgboost.\n",
    "    X_val_test (DataFrame): Clases actuales\n",
    "    y_val_test (ndarray): Probabildades de clase\n",
    "    '''\n",
    "    print(\n",
    "        \"roc_auc_score: {}\".format(\n",
    "            np.round(roc_auc_score(y_val_test, model.predict_proba(X_val_test)[:,1]), 3)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "def fun_graficar_error_clasificacion(model, X_val_test, y_val_test):\n",
    "    '''Graficar error de clasificación\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model (Estimator): Fitted estimator\n",
    "    X_test (DataFrame): Predictores del conjunto de validación o prueba.\n",
    "    y_test (ndarray): Clases del conjunto de validación o prueba.\n",
    "    '''\n",
    "    fig, ax = plt.subplots(figsize = (7,6))\n",
    "    cpe_viz = ClassPredictionError(model, classes = ['no', 'yes'])\n",
    "    cpe_viz.fit(X_train, y_train)\n",
    "    cpe_viz.score(X_val_test, y_val_test)\n",
    "    cpe_viz.show();\n",
    "\n",
    "def fun_graficar_importancias(model):\n",
    "    '''Graficar importancia de características\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model (Estimator): Fitted estimator de un DecisionTree, Random Forest o xgboost.\n",
    "    '''\n",
    "    fig, ax = plt.subplots(figsize = (8,6))\n",
    "    viz = FeatureImportances(model)\n",
    "    viz.fit(X_train, y_train)\n",
    "    viz.show();\n",
    "    \n",
    "def fun_graficar_discrimination_threshold(model, X_val_test, y_val_test):\n",
    "    '''Graficar relación de precision y recall con distintos puntos de corte\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model (Estimator): Fitted estimator de un DecisionTree, Random Forest o xgboost.\n",
    "    X_val_test (DataFrame): Clases actuales\n",
    "    y_val_test (ndarray): Probabildades de clase\n",
    "    '''\n",
    "    fig, ax = plt.subplots(figsize = (8,6))\n",
    "    visualizer = DiscriminationThreshold(\n",
    "        model,\n",
    "        exclude = [\"queue_rate\"]\n",
    "    )\n",
    "    visualizer.fit(X_val_test, y_val_test)\n",
    "    visualizer.show();     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602f3695-97d3-4ee7-a1e8-6a5d96b0b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar matriz de confusión\n",
    "fun_graficar_matriz_confusion(____________, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da87bb0b-d21e-453f-b63f-1f57a6b2bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar reporte de clasificación\n",
    "fun_graficar_reporte_clasificacion(____________, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8330298d-a51b-4e45-9d1b-027f13e92ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar curva de precision y recall\n",
    "fun_graficar_curva_precision_recall(____________, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283523c5-166b-43f8-898c-77187b829243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar curva ROC AUC\n",
    "fun_graficar_curva_roc(____________, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a4894-10c4-4b47-8fc3-df0b00c82228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir el ROC AUC score\n",
    "fun_imprimir_roc_auc_score(____________, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0a3f9d-e200-4da1-89ac-64161c1d259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar curva de discriminación del punto de corte.\n",
    "fun_graficar_discrimination_threshold(____________, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be0ea9f-6817-4f2b-91ff-91cdb2cb3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificar con un punto de corte óptimo\n",
    "def fun_predict_with_threshold(model, threshold = 0.45):\n",
    "    '''Predice la clase del cliente utilizando un threshold\n",
    "    \n",
    "    Permite predecir la clase de un cliente utilizando otros \n",
    "    puntos de corte (threshold) que sean diferentes a 0.5.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: Fitted estimator\n",
    "    threshold (float): Punto de corte entre 0 y 1.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ndarray:\n",
    "        Regresa un numpy array con el valor de la clase 0 ó 1\n",
    "    '''\n",
    "    return np.where( model.predict_proba(X_val)[:,1] < threshold, 0, 1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef50c99f-17e4-43c8-8a51-009490eb2c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular clases con un punto de corte\n",
    "y_pred_thr = fun_predict_with_threshold(__________, threshold = _______)\n",
    "# Mostrar primeros 20 clientes\n",
    "y_pred_thr[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf08b3-23f9-4429-aa1f-a6a25518f08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar matriz de confusión\n",
    "fun_graficar_matriz_confusion(__________, X_val, __________)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19399e8a-22fd-4d78-98bd-4a7537815721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar reporte de clasificación\n",
    "fun_graficar_reporte_clasificacion(__________, X_val, __________)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2241db-d827-4f58-be87-c32b3810d62b",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "* Comparando con el árbol de decisión y el xgboost, cómo te fue con este modelo. \n",
    "* ¿Cuánto te dio el AUC score? ¿Qué implica esto con respecto a los otros modelos?\n",
    "* ¿Escogerías un punto de corte diferente? ¿Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf254b9b-6396-43dc-b2b9-38b31ce38360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
